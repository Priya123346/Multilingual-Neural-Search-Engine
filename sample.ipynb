{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fe16a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.6)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.10.5)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.11.0.post1)\n",
      "Requirement already satisfied: langdetect in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.0.9)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
      "Requirement already satisfied: six in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langdetect) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kotag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.14)\n",
      "Using cached sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-5.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\kotag\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy matplotlib sentence-transformers faiss-cpu langdetect scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3358d569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data_train.csv', encoding='latin1')\n",
    "df = df.sample(frac=0.01, random_state=42)\n",
    "df.dropna(inplace=True)\n",
    "questions = df.question1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f2c2001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['How do I play Pokémon GO in Korea?',\n",
       "       'What are some of the best side dishes for crab cakes?',\n",
       "       'Which is more advisable and better material for a crash test in automobiles, ductile or brittle?',\n",
       "       'How do I improve logical programming skills?',\n",
       "       'How close we are to see 3rd world war?'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e6b7805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies installed successfully\n"
     ]
    }
   ],
   "source": [
    "# No longer needed - sentence-transformers replaces TensorFlow Hub\n",
    "print(\"Dependencies installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0eee1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dependencies ready\n"
     ]
    }
   ],
   "source": [
    "# No longer needed - using sentence-transformers instead\n",
    "print(\"All dependencies ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35185e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kotag\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langdetect import detect\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class Multilingual_Encoder:\n",
    "    \"\"\"\n",
    "    Improved multilingual encoder using sentence-transformers\n",
    "    Supports 50+ languages with high-quality embeddings\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name='paraphrase-multilingual-MiniLM-L12-v2'):\n",
    "        \"\"\"\n",
    "        Initialize with a multilingual model\n",
    "        Options:\n",
    "        - 'paraphrase-multilingual-MiniLM-L12-v2' (lightweight, 384-dim)\n",
    "        - 'distiluse-base-multilingual-cased-v2' (larger, 512-dim)\n",
    "        - 'xlm-r-distilroberta-base' (multilingual)\n",
    "        \"\"\"\n",
    "        print(f\"Loading model: {model_name}\")\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        print(f\"Model loaded. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "    \n",
    "    def encode(self, text):\n",
    "        \"\"\"Encode text to embedding vector\"\"\"\n",
    "        if isinstance(text, list):\n",
    "            return self.model.encode(text, convert_to_numpy=True)\n",
    "        else:\n",
    "            return self.model.encode([text], convert_to_numpy=True)[0]\n",
    "    \n",
    "    def encode_batch(self, texts, batch_size=32):\n",
    "        \"\"\"Encode multiple texts efficiently\"\"\"\n",
    "        return self.model.encode(texts, batch_size=batch_size, convert_to_numpy=True)\n",
    "\n",
    "def detect_language(text):\n",
    "    \"\"\"Detect the language of input text\"\"\"\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "        return lang\n",
    "    except:\n",
    "        return \"unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73841868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "class Multilingual_FAISS:\n",
    "    \"\"\"\n",
    "    Improved FAISS index with cosine similarity (better for semantic search)\n",
    "    Supports efficient similarity search\n",
    "    \"\"\"\n",
    "    def __init__(self, dimensions):\n",
    "        self.dimensions = dimensions\n",
    "        self.index = faiss.IndexFlatIP(dimensions)  # Inner product (cosine similarity)\n",
    "        self.vectors = {}\n",
    "        self.counter = 0\n",
    "        self.texts = []\n",
    "    \n",
    "    def add(self, text, v):\n",
    "        \"\"\"Add text and its embedding to the index\"\"\"\n",
    "        # Normalize the vector for cosine similarity\n",
    "        v_normalized = normalize(v.reshape(1, -1), norm='l2')[0]\n",
    "        v_normalized = v_normalized.reshape(1, -1).astype('float32')\n",
    "        \n",
    "        self.index.add(v_normalized)\n",
    "        self.vectors[self.counter] = (text, v_normalized[0])\n",
    "        self.texts.append(text)\n",
    "        self.counter += 1\n",
    "    \n",
    "    def add_batch(self, texts, vectors):\n",
    "        \"\"\"Add multiple texts and embeddings at once (faster)\"\"\"\n",
    "        vectors_normalized = normalize(vectors, norm='l2')\n",
    "        vectors_normalized = vectors_normalized.astype('float32')\n",
    "        \n",
    "        self.index.add(vectors_normalized)\n",
    "        for i, (text, vec) in enumerate(zip(texts, vectors_normalized)):\n",
    "            self.vectors[self.counter] = (text, vec)\n",
    "            self.texts.append(text)\n",
    "            self.counter += 1\n",
    "    \n",
    "    def search(self, v, k=5, threshold=0.3):\n",
    "        \"\"\"\n",
    "        Search for similar questions\n",
    "        Args:\n",
    "            v: query embedding vector\n",
    "            k: number of results to return\n",
    "            threshold: minimum similarity score (0-1)\n",
    "        \"\"\"\n",
    "        # Normalize query vector\n",
    "        v_normalized = normalize(v.reshape(1, -1), norm='l2')[0]\n",
    "        v_normalized = v_normalized.reshape(1, -1).astype('float32')\n",
    "        \n",
    "        # Search\n",
    "        distances, item_idx = self.index.search(v_normalized, k)\n",
    "        \n",
    "        results = []\n",
    "        print(f\"\\n{'Rank':<5} {'Similarity':<12} {'Result':<100}\")\n",
    "        print(\"-\" * 120)\n",
    "        \n",
    "        for rank, (d, i) in enumerate(zip(distances[0], item_idx[0]), 1):\n",
    "            if i == -1:\n",
    "                break\n",
    "            \n",
    "            # Convert cosine similarity to percentage\n",
    "            similarity = float(d) * 100\n",
    "            \n",
    "            if similarity >= threshold * 100:\n",
    "                text, vec = self.vectors[i]\n",
    "                results.append((text, similarity))\n",
    "                print(f\"{rank:<5} {similarity:>10.2f}% {text[:95]:<100}\")\n",
    "        \n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29c3fff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing multilingual encoder...\n",
      "Loading model: paraphrase-multilingual-MiniLM-L12-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae7f3cf4945470285a403a57cb49b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3fe5b3cb9a4243904583d6462f4878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6818b0a8204479866ef52236e23baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35dcb35577c1401b93062a936b1cee21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c47ed18f194e98a5903c0fbd20cd5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47010f0d17574263ba48be438f648a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6dd0f974f0d49df81956e33ce51f7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a78efb1a804418b91db395947c17c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8bb7f6fd23419484e6e0ff835a0e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998002bee7e94ce69da6c988fbe9c487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded. Embedding dimension: 384\n",
      "Embedding dimension: 384\n",
      "\n",
      "Encoding 4043 questions...\n",
      "Building FAISS index...\n",
      "Index built with 4043 questions\n",
      "Building FAISS index...\n",
      "Index built with 4043 questions\n"
     ]
    }
   ],
   "source": [
    "# Initialize the improved multilingual encoder and build index\n",
    "print(\"Initializing multilingual encoder...\")\n",
    "encoder = Multilingual_Encoder('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Get embedding dimension\n",
    "dimension = encoder.model.get_sentence_embedding_dimension()\n",
    "print(f\"Embedding dimension: {dimension}\")\n",
    "\n",
    "# Create FAISS index\n",
    "faiss_index = Multilingual_FAISS(dimension)\n",
    "\n",
    "# Encode all questions in batch (much faster than one-by-one)\n",
    "print(f\"\\nEncoding {len(questions)} questions...\")\n",
    "question_embeddings = encoder.encode_batch(questions, batch_size=64)\n",
    "\n",
    "# Add all to index at once\n",
    "print(\"Building FAISS index...\")\n",
    "faiss_index.add_batch(questions, question_embeddings)\n",
    "print(f\"Index built with {faiss_index.counter} questions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2c31753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "TEST 1: English Query\n",
      "========================================================================================================================\n",
      "Query: How to learn machine learning?\n",
      "Detected Language: en\n",
      "\n",
      "Rank  Similarity   Result                                                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "1          99.32% How can I learn machine learning?                                                                   \n",
      "2          73.94% What are the best books about machine learning?                                                     \n",
      "3          70.24% What are some good Machine Learning books for a beginner?                                           \n",
      "4          51.63% What is the basic difference between inferential statistics and machine learning?                   \n",
      "5          50.47% How do I improve my learning and understanding capabilities?                                        \n",
      "\n",
      "========================================================================================================================\n",
      "TEST 2: Spanish Query\n",
      "========================================================================================================================\n",
      "Query: ¿Cómo aprender programación?\n",
      "Detected Language: es\n",
      "Query: How to learn machine learning?\n",
      "Detected Language: en\n",
      "\n",
      "Rank  Similarity   Result                                                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "1          99.32% How can I learn machine learning?                                                                   \n",
      "2          73.94% What are the best books about machine learning?                                                     \n",
      "3          70.24% What are some good Machine Learning books for a beginner?                                           \n",
      "4          51.63% What is the basic difference between inferential statistics and machine learning?                   \n",
      "5          50.47% How do I improve my learning and understanding capabilities?                                        \n",
      "\n",
      "========================================================================================================================\n",
      "TEST 2: Spanish Query\n",
      "========================================================================================================================\n",
      "Query: ¿Cómo aprender programación?\n",
      "Detected Language: es\n",
      "\n",
      "Rank  Similarity   Result                                                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "1          85.47% From where can I learn programming?                                                                 \n",
      "2          85.23% How to learn coding?                                                                                \n",
      "3          78.59% What is best way to start learning programming?                                                     \n",
      "4          74.74% What is the best and most efficient way to learn and master a programming language?                 \n",
      "5          66.04% How do I develop myself as a programmer?                                                            \n",
      "\n",
      "========================================================================================================================\n",
      "TEST 3: Hindi Query\n",
      "========================================================================================================================\n",
      "Query: प्रोग्रामिंग कैसे सीखें\n",
      "Detected Language: hi\n",
      "\n",
      "Rank  Similarity   Result                                                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "1          81.83% From where can I learn programming?                                                                 \n",
      "2          80.08% How to learn coding?                                                                                \n",
      "3          73.66% What is best way to start learning programming?                                                     \n",
      "4          71.57% What is the best and most efficient way to learn and master a programming language?                 \n",
      "5          64.78% Fundamentally, what is programming?                                                                 \n",
      "\n",
      "Rank  Similarity   Result                                                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "1          85.47% From where can I learn programming?                                                                 \n",
      "2          85.23% How to learn coding?                                                                                \n",
      "3          78.59% What is best way to start learning programming?                                                     \n",
      "4          74.74% What is the best and most efficient way to learn and master a programming language?                 \n",
      "5          66.04% How do I develop myself as a programmer?                                                            \n",
      "\n",
      "========================================================================================================================\n",
      "TEST 3: Hindi Query\n",
      "========================================================================================================================\n",
      "Query: प्रोग्रामिंग कैसे सीखें\n",
      "Detected Language: hi\n",
      "\n",
      "Rank  Similarity   Result                                                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "1          81.83% From where can I learn programming?                                                                 \n",
      "2          80.08% How to learn coding?                                                                                \n",
      "3          73.66% What is best way to start learning programming?                                                     \n",
      "4          71.57% What is the best and most efficient way to learn and master a programming language?                 \n",
      "5          64.78% Fundamentally, what is programming?                                                                 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('From where can I learn programming?', 81.83436393737793),\n",
       " ('How to learn coding?', 80.07534742355347),\n",
       " ('What is best way to start learning programming?', 73.65648746490479),\n",
       " ('What is the best and most efficient way to learn and master a programming language?',\n",
       "  71.57421708106995),\n",
       " ('Fundamentally, what is programming?', 64.77685570716858)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 1: English query\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"TEST 1: English Query\")\n",
    "print(\"=\"*120)\n",
    "query1 = \"How to learn machine learning?\"\n",
    "lang1 = detect_language(query1)\n",
    "print(f\"Query: {query1}\")\n",
    "print(f\"Detected Language: {lang1}\")\n",
    "\n",
    "query_vec1 = encoder.encode(query1)\n",
    "faiss_index.search(query_vec1, k=5, threshold=0.2)\n",
    "\n",
    "# Test 2: Spanish query\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"TEST 2: Spanish Query\")\n",
    "print(\"=\"*120)\n",
    "query2 = \"¿Cómo aprender programación?\"\n",
    "lang2 = detect_language(query2)\n",
    "print(f\"Query: {query2}\")\n",
    "print(f\"Detected Language: {lang2}\")\n",
    "\n",
    "query_vec2 = encoder.encode(query2)\n",
    "faiss_index.search(query_vec2, k=5, threshold=0.2)\n",
    "\n",
    "# Test 3: Hindi query\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"TEST 3: Hindi Query\")\n",
    "print(\"=\"*120)\n",
    "query3 = \"प्रोग्रामिंग कैसे सीखें\"\n",
    "lang3 = detect_language(query3)\n",
    "print(f\"Query: {query3}\")\n",
    "print(f\"Detected Language: {lang3}\")\n",
    "\n",
    "query_vec3 = encoder.encode(query3)\n",
    "faiss_index.search(query_vec3, k=5, threshold=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb768182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "TEST 3: Hindi Query\n",
      "========================================================================================================================\n",
      "Query: प्रोग्रामिंग कैसे सीखें\n",
      "Detected Language: hi\n",
      "\n",
      "Rank  Similarity   Result                                                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "1          81.83% From where can I learn programming?                                                                 \n",
      "2          80.08% How to learn coding?                                                                                \n",
      "3          73.66% What is best way to start learning programming?                                                     \n",
      "4          71.57% What is the best and most efficient way to learn and master a programming language?                 \n",
      "5          64.78% Fundamentally, what is programming?                                                                 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('From where can I learn programming?', 81.83436393737793),\n",
       " ('How to learn coding?', 80.07534742355347),\n",
       " ('What is best way to start learning programming?', 73.65648746490479),\n",
       " ('What is the best and most efficient way to learn and master a programming language?',\n",
       "  71.57421708106995),\n",
       " ('Fundamentally, what is programming?', 64.77685570716858)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Test 3: Hindi query\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"TEST 3: Hindi Query\")\n",
    "print(\"=\"*120)\n",
    "query3 = \"प्रोग्रामिंग कैसे सीखें\"\n",
    "lang3 = detect_language(query3)\n",
    "print(f\"Query: {query3}\")\n",
    "print(f\"Detected Language: {lang3}\")\n",
    "\n",
    "query_vec3 = encoder.encode(query3)\n",
    "faiss_index.search(query_vec3, k=5, threshold=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0ec6638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "DATASET LANGUAGE ANALYSIS\n",
      "========================================================================================================================\n",
      "Total questions in dataset: 4043\n",
      "\n",
      "Languages found in first 100 questions:\n",
      "  en: 98\n",
      "  es: 1\n",
      "  pt: 1\n",
      "\n",
      "Languages found in first 100 questions:\n",
      "  en: 98\n",
      "  es: 1\n",
      "  pt: 1\n"
     ]
    }
   ],
   "source": [
    "# Analyze dataset languages\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"DATASET LANGUAGE ANALYSIS\")\n",
    "print(\"=\"*120)\n",
    "print(f\"Total questions in dataset: {len(questions)}\")\n",
    "\n",
    "# Sample language detection\n",
    "sample_questions = questions[:min(100, len(questions))]\n",
    "languages_detected = [detect_language(q) for q in sample_questions]\n",
    "\n",
    "from collections import Counter\n",
    "lang_counts = Counter(languages_detected)\n",
    "print(f\"\\nLanguages found in first 100 questions:\")\n",
    "for lang, count in lang_counts.most_common():\n",
    "    print(f\"  {lang}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf1bd970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive search function\n",
    "def multilingual_search(query, top_k=5, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Perform multilingual semantic search\n",
    "    \n",
    "    Args:\n",
    "        query: Search query in any language\n",
    "        top_k: Number of results to return\n",
    "        threshold: Minimum similarity score (0-1)\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples (text, similarity_score)\n",
    "    \"\"\"\n",
    "    detected_lang = detect_language(query)\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(f\"Detected Language: {detected_lang}\")\n",
    "    print(\"-\" * 120)\n",
    "    \n",
    "    query_vec = encoder.encode(query)\n",
    "    results = faiss_index.search(query_vec, k=top_k, threshold=threshold)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "# results = multilingual_search(\"What is Python?\", top_k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe80fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e00e060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc821a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
